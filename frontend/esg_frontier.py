# -*- coding: utf-8 -*-
"""Copy of ESG_Efficient_Frontier (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bG0n-GULNFbZaeO_cUeH45LwMB39N2Ly
"""

import yfinance as yf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.optimize import minimize
import datetime

start_date = pd.to_datetime("2019-09-30")
end_date = pd.to_datetime("2025-01-02")

price_data = pd.DataFrame()
tickers = ["CROX", "DECK", "EME", "COST", "DE", 'NVDA']
for t in tickers:
  price_data[t] = yf.Ticker(t).history(start=start_date, end=end_date)['Close']
price_data.index = price_data.index.date

# 3 month T-bill, daily yield
risk_free_rate = (yf.Ticker("^IRX").history(start=start_date + pd.DateOffset(days=1), end=end_date)['Close'] / 100.0) / 252
risk_free_rate.index = risk_free_rate.index.date

risk_free_rate

price_data

ef_start_date = datetime.date(2023, 1, 2)
ef_end_date = datetime.date(2024, 1, 2)

def calc_stats(price_data, risk_free_rate):
  """
  Calculates mean daily excess returns and cov matrix of daily excess returns
  """
  returns = price_data.pct_change().dropna()
  excess_returns = returns.sub(risk_free_rate, axis=0)
  mean_excess_returns = excess_returns.mean()
  cov_matrix = excess_returns.cov()
  return mean_excess_returns, cov_matrix

_price_data = price_data.loc[ef_start_date:ef_end_date]
_risk_free_rate = risk_free_rate.loc[ef_start_date:ef_end_date]
r, Sigma = calc_stats(_price_data, _risk_free_rate)
r, Sigma

len(_price_data)

def portfolio_sharpe_annual(weights, mean_excess_returns, cov_matrix):
  portfolio_return = np.dot(weights, mean_excess_returns) # w^T r
  portfolio_volatility = np.sqrt(weights.T @ cov_matrix @ weights) # sqrt(w^T Sigma w)
  return (portfolio_return / portfolio_volatility) * np.sqrt(252)

def asset_sharpe_annual(mean_excess_returns, cov_matrix, ticker):
  return (mean_excess_returns[ticker] / np.sqrt(cov_matrix.loc[ticker, ticker])) * np.sqrt(252)

portfolio_sharpe_annual(np.ones(len(tickers)).T / len(tickers), r, Sigma) # reasonable

def esg_ef_optimizer(mean_excess_returns, cov_matrix, esg_scores, target_esg):
  n_assets = len(mean_excess_returns)

  def objective_sharpe(weights):
    portfolio_return = np.dot(weights, mean_excess_returns)
    portfolio_volatility = np.sqrt(weights.T @ cov_matrix @ weights)
    return - (portfolio_return / portfolio_volatility) * np.sqrt(252) # - since we are using minimize

  def constraint_esg(weights):
    portfolio_esg = np.dot(weights, esg_scores)
    return target_esg - portfolio_esg

  constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}, {'type': 'eq', 'fun': constraint_esg}) # weights sum to 1, target esg
  bounds = tuple((0.01, 1) for _ in range(n_assets))  # long only, min alloc 1%

  init_weights = np.ones(n_assets) / n_assets
  result = minimize(objective_sharpe, init_weights, bounds=bounds, constraints=constraints)
  return result.x, -result.fun

esg_scores = np.array([0.62, 0.63, 0.56, 0.72, 0.73])
target_esg = 0.65
esg_ef_optimizer(r, Sigma, esg_scores, target_esg)

def markowitz_max_sharpe_optimizer(mean_excess_returns, cov_matrix):
  n_assets = len(mean_excess_returns)

  def objective_sharpe(weights):
    portfolio_return = np.dot(weights, mean_excess_returns)
    portfolio_volatility = np.sqrt(weights.T @ cov_matrix @ weights)
    return - (portfolio_return / portfolio_volatility) * np.sqrt(252) # - since we are using minimize

  constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},) # weights sum to 1
  bounds = tuple((0.01, 1) for _ in range(n_assets))  # long only, min alloc 1%

  init_weights = np.ones(n_assets) / n_assets
  result = minimize(objective_sharpe, init_weights, bounds=bounds, constraints=constraints)
  return result.x, -result.fun

ms_weights, max_sharpe = markowitz_max_sharpe_optimizer(r, Sigma)
ms_portfolio_esg = np.dot(ms_weights, esg_scores)
ms_weights, max_sharpe, ms_portfolio_esg

step = 0.005
target_esgs = np.round(np.arange(min(esg_scores) + step, max(esg_scores) - step, step), 3)
target_esgs

sharpes = []
for target in target_esgs:
  _, sharpe = esg_ef_optimizer(r, Sigma, esg_scores, target)
  sharpes.append(sharpe)
sharpes

indiv_sharpes = []
for t in tickers:
  indiv_sharpes.append(asset_sharpe_annual(r, Sigma, t))

plt.figure(figsize=(10, 6))
plt.plot(target_esgs, sharpes, ls="-.", label="ESG-Efficient Frontier")
plt.scatter(esg_scores, indiv_sharpes, color="red", s=100, zorder=5)
for esg, sharpe, ticker in zip(esg_scores, indiv_sharpes, tickers):
  plt.text(esg, sharpe + 0.1, f"{ticker}", ha='center', fontsize=10)
plt.scatter([ms_portfolio_esg], [max_sharpe], color="red", marker="*", s=100, zorder=5)
plt.text(ms_portfolio_esg, max_sharpe - 0.1, f"Tangency", ha="center", fontsize=10)
plt.xlabel("ESG Score")
plt.ylabel("Annualized Sharpe Ratio")
plt.title("SIGEFXXXQ ESG-Efficient Frontier: FY23")
plt.grid(True)
plt.show()

"""5y backtests"""

bt_start_date = datetime.date(2019, 10, 1)
bt_end_date = risk_free_rate.index[-1]
rebal_dates = [
    "2020-01-02", "2020-04-01", "2020-07-01", "2020-10-01", "2021-01-04",
    "2021-04-01", "2021-07-01", "2021-10-01", "2022-01-03", "2022-04-01",
    "2022-07-01", "2022-10-03", "2023-01-02", "2023-04-03", "2023-07-03",
    "2023-10-02", "2024-01-02", "2024-04-01", "2024-07-01", "2024-10-01",
]

rebal_dates = [datetime.datetime.strptime(d, "%Y-%m-%d").date() for d in rebal_dates]
dates = [bt_start_date] + rebal_dates
dates

# SIGEF65TQ
df_weights_65 = pd.DataFrame(index=risk_free_rate.index[risk_free_rate.index >= dates[1]], columns=tickers)
df_weights_65

target_esg = 0.65
for i in range(len(dates) - 1):
  _price_data = price_data.loc[dates[i]:dates[i + 1]]
  _risk_free_rate = risk_free_rate.loc[dates[i]:dates[i + 1]]
  r, Sigma = calc_stats(_price_data, _risk_free_rate)
  weights, _ = esg_ef_optimizer(r, Sigma, esg_scores, target_esg)
  if i == len(dates) - 2:
    df_weights_65.loc[dates[i + 1]:bt_end_date] = weights
  else:
    df_weights_65.loc[dates[i + 1]:dates[i + 2]] = weights
df_weights_65

df_returns_65 = price_data.pct_change().dropna().loc[dates[1]:] * df_weights_65
df_returns_65["SIGEF65TQ_DAILY"] = df_returns_65.sum(axis=1)
df_returns_65["SIGEF65TQ_CUM"] = (1 + df_returns_65["SIGEF65TQ_DAILY"]).cumprod() - 1
df_returns_65

df_returns_65["SIGEF65TQ_CUM"].plot()

df_weights_70 = pd.DataFrame(index=risk_free_rate.index[risk_free_rate.index >= dates[1]], columns=tickers)
df_weights_70

target_esg = 0.7
for i in range(len(dates) - 1):
  _price_data = price_data.loc[dates[i]:dates[i + 1]]
  _risk_free_rate = risk_free_rate.loc[dates[i]:dates[i + 1]]
  r, Sigma = calc_stats(_price_data, _risk_free_rate)
  weights, _ = esg_ef_optimizer(r, Sigma, esg_scores, target_esg)
  if i == len(dates) - 2:
    df_weights_70.loc[dates[i + 1]:bt_end_date] = weights
  else:
    df_weights_70.loc[dates[i + 1]:dates[i + 2]] = weights
df_weights_70

df_returns_70 = price_data.pct_change().dropna().loc[dates[1]:] * df_weights_70
df_returns_70["SIGEF70TQ_DAILY"] = df_returns_70.sum(axis=1)
df_returns_70["SIGEF70TQ_CUM"] = (1 + df_returns_70["SIGEF70TQ_DAILY"]).cumprod() - 1
df_returns_70